{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e40ca4ed-0ec5-4147-afd7-faf2b679ffed",
   "metadata": {},
   "source": [
    "# Module 1 Homework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb27f6b-9236-44e0-a421-42b90f486ae5",
   "metadata": {},
   "source": [
    "## Docker & SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05694206-3b32-4513-b183-b2227309aeb0",
   "metadata": {},
   "source": [
    "**Question 1. Knowing docker tags**\n",
    "Run the command to get information on Docker\n",
    "\n",
    "docker --help\n",
    "\n",
    "Now run the command to get help on the \"docker build\" command:\n",
    "\n",
    "docker build --help\n",
    "\n",
    "Do the same for \"docker run\".\n",
    "\n",
    "Which tag has the following text? - Automatically remove the container when it exits\n",
    "\n",
    "**ANSWER: --rm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf76ae5-4ca3-4fff-b36c-9c596548ef98",
   "metadata": {},
   "source": [
    "## Question 2. Understanding docker first run\n",
    "Run docker with the python:3.9 image in an interactive mode and the entrypoint of bash. Now check the python modules that are installed ( use pip list ).\n",
    "\n",
    "What is the version of the package wheel?\n",
    "\n",
    "**ANSWER: 0.42.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5ea890-1f8a-42e8-97f4-6b4bd46851a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_csv_gz(input_file, output_file):\n",
    "    with gzip.open(input_file, 'rb') as f_in:\n",
    "        with open(output_file, 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29352ce5-1cea-4dfe-a545-21698ad19f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8635d624-73a3-481b-b060-d1d3dadfc874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping green_tripdata_2019_9.csv.gz to green_tripdata_2019_9.csv...\n",
      "Unzip complete.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-09.csv.gz'\n",
    "green_trip_data_csv = 'green_tripdata_2019_9.csv'\n",
    "green_trip_data_csv_gz  = 'green_tripdata_2019_9.csv.gz'\n",
    "    \n",
    "# os.system(f\"wget {url} -O {green_trip_data_csv_gz}\")\n",
    "print(f\"Unzipping {green_trip_data_csv_gz} to {green_trip_data_csv}...\")\n",
    "unzip_csv_gz(green_trip_data_csv_gz, green_trip_data_csv)\n",
    "print(\"Unzip complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6de51d3c-ce14-4578-9065-979cf3820423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-01-25 12:37:33--  https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.139.32, 52.217.169.120, 52.217.199.152, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.139.32|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12322 (12K) [application/octet-stream]\n",
      "Saving to: ‘taxi_zone_lookup.csv’\n",
      "\n",
      "     0K .......... ..                                         100% 1.45M=0.008s\n",
      "\n",
      "2024-01-25 12:37:34 (1.45 MB/s) - ‘taxi_zone_lookup.csv’ saved [12322/12322]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv'\n",
    "taxi_zone_lookup = 'taxi_zone_lookup.csv'\n",
    "    \n",
    "os.system(f\"wget {url} -O {taxi_zone_lookup}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c12020ea-a05f-4eee-9121-d88fbbef0f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x7fcfa8477ac0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8471cee2-e09a-41e3-ba83-5d11fe651058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-01 00:10:53</td>\n",
       "      <td>2019-09-01 00:23:46</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>189</td>\n",
       "      <td>5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-01 00:31:22</td>\n",
       "      <td>2019-09-01 00:44:37</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>225</td>\n",
       "      <td>5</td>\n",
       "      <td>3.20</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-09-01 00:50:24</td>\n",
       "      <td>2019-09-01 01:03:20</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>61</td>\n",
       "      <td>5</td>\n",
       "      <td>2.99</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID lpep_pickup_datetime lpep_dropoff_datetime store_and_fwd_flag  \\\n",
       "0         2  2019-09-01 00:10:53   2019-09-01 00:23:46                  N   \n",
       "1         2  2019-09-01 00:31:22   2019-09-01 00:44:37                  N   \n",
       "2         2  2019-09-01 00:50:24   2019-09-01 01:03:20                  N   \n",
       "\n",
       "   RatecodeID  PULocationID  DOLocationID  passenger_count  trip_distance  \\\n",
       "0           1            65           189                5           2.00   \n",
       "1           1            97           225                5           3.20   \n",
       "2           1            37            61                5           2.99   \n",
       "\n",
       "   fare_amount  extra  mta_tax  tip_amount  tolls_amount  ehail_fee  \\\n",
       "0         10.5    0.5      0.5        2.36           0.0        NaN   \n",
       "1         12.0    0.5      0.5        0.00           0.0        NaN   \n",
       "2         12.0    0.5      0.5        0.00           0.0        NaN   \n",
       "\n",
       "   improvement_surcharge  total_amount  payment_type  trip_type  \\\n",
       "0                    0.3         14.16             1          1   \n",
       "1                    0.3         13.30             2          1   \n",
       "2                    0.3         13.30             2          1   \n",
       "\n",
       "   congestion_surcharge  \n",
       "0                   0.0  \n",
       "1                   0.0  \n",
       "2                   0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(green_trip_data_csv, nrows=100)\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5d3df8f-e6e1-453d-a789-ac1b1c82a288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"green_trip_data\" (\n",
      "\"VendorID\" INTEGER,\n",
      "  \"lpep_pickup_datetime\" TIMESTAMP,\n",
      "  \"lpep_dropoff_datetime\" TIMESTAMP,\n",
      "  \"store_and_fwd_flag\" TEXT,\n",
      "  \"RatecodeID\" INTEGER,\n",
      "  \"PULocationID\" INTEGER,\n",
      "  \"DOLocationID\" INTEGER,\n",
      "  \"passenger_count\" INTEGER,\n",
      "  \"trip_distance\" REAL,\n",
      "  \"fare_amount\" REAL,\n",
      "  \"extra\" REAL,\n",
      "  \"mta_tax\" REAL,\n",
      "  \"tip_amount\" REAL,\n",
      "  \"tolls_amount\" REAL,\n",
      "  \"ehail_fee\" REAL,\n",
      "  \"improvement_surcharge\" REAL,\n",
      "  \"total_amount\" REAL,\n",
      "  \"payment_type\" INTEGER,\n",
      "  \"trip_type\" INTEGER,\n",
      "  \"congestion_surcharge\" REAL\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "table = 'green_trip_data'\n",
    "df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "print(pd.io.sql.get_schema(df, name=table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd6efff7-1e1a-4ddd-be18-2f0c428255fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iter = pd.read_csv(green_trip_data_csv, iterator=True, chunksize=100000)\n",
    "df = next(df_iter)\n",
    "df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "df.head(n=0).to_sql(name=table, con=engine, if_exists='replace')\n",
    "df.to_sql(name=table, con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00e349bb-9370-4cf4-8af0-6417c9e563d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk..., and it took 16.68092942237854\n",
      "Inserted another chunk..., and it took 16.100798845291138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6537/2660871614.py:5: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = next(df_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted another chunk..., and it took 16.381404161453247\n",
      "Inserted another chunk..., and it took 6.977352619171143\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     t_start \u001b[38;5;241m=\u001b[39m time()\n\u001b[0;32m----> 5\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     df\u001b[38;5;241m.\u001b[39mlpep_pickup_datetime \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mlpep_pickup_datetime)\n\u001b[1;32m      7\u001b[0m     df\u001b[38;5;241m.\u001b[39mlpep_dropoff_datetime \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mlpep_dropoff_datetime)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1668\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1666\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   1667\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1668\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1669\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1670\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1777\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1775\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[0;32m-> 1777\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.15/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:868\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "while True:\n",
    "    t_start = time()\n",
    "    \n",
    "    df = next(df_iter)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.to_sql(name=table, con=engine, if_exists='append')\n",
    "\n",
    "    t_end = time()\n",
    "\n",
    "    print(f\"Inserted another chunk..., and it took {t_end - t_start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd96ae07-3987-4aaf-8c55-ec56ba6a1938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID Borough                     Zone service_zone\n",
       "0           1     EWR           Newark Airport          EWR\n",
       "1           2  Queens              Jamaica Bay    Boro Zone\n",
       "2           3   Bronx  Allerton/Pelham Gardens    Boro Zone"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(taxi_zone_lookup, nrows=100)\n",
    "df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "49d7efbe-3b54-4fba-ba19-c169dcad1a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"taxi_zone_lookup\" (\n",
      "\"LocationID\" INTEGER,\n",
      "  \"Borough\" TEXT,\n",
      "  \"Zone\" TEXT,\n",
      "  \"service_zone\" TEXT\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "table_2 = 'taxi_zone_lookup'\n",
    "print(pd.io.sql.get_schema(df, name=table_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4773495a-ac94-44b9-9ce0-884e2868fd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(265, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iter = pd.read_csv(taxi_zone_lookup)\n",
    "df_iter.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92d063bb-039e-4961-a2b2-f9ddd134966c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_iter.head(n=0).to_sql(name=table_2, con=engine, if_exists='replace')\n",
    "df_iter.to_sql(name=table_2, con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c768523-ec65-44d2-a4bb-31eea0ffdc4b",
   "metadata": {},
   "source": [
    "# Question 3. Count records\n",
    "How many taxi trips were totally made on September 18th 2019?\n",
    "\n",
    "Tip: started and finished on 2019-09-18.\n",
    "\n",
    "Remember that lpep_pickup_datetime and lpep_dropoff_datetime columns are in the format timestamp (date and hour+min+sec) and not in date.\n",
    "\n",
    "**ANSWER: 15612**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1952081a-8daf-4a27-9705-2bcc7fceed4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(1) FROM green_trip_data \n",
      "WHERE \n",
      "\tlpep_pickup_datetime BETWEEN '2019-09-18 00:00:00' AND '2019-09-18 23:59:59' AND \n",
      "\tlpep_dropoff_datetime BETWEEN '2019-09-18 00:00:00' AND '2019-09-18 23:59:59';\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL STATEMENT\n",
    "print(\"\"\"SELECT COUNT(1) FROM green_trip_data \n",
    "WHERE \n",
    "\tlpep_pickup_datetime BETWEEN '2019-09-18 00:00:00' AND '2019-09-18 23:59:59' AND \n",
    "\tlpep_dropoff_datetime BETWEEN '2019-09-18 00:00:00' AND '2019-09-18 23:59:59';\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2a022a-4b97-48f2-b013-7c624609a367",
   "metadata": {},
   "source": [
    "## Question 4. Largest trip for each day\n",
    "Which was the pick up day with the largest trip distance Use the pick up time for your calculations.\n",
    "\n",
    "**ANSWER: 2019-09-26**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "15a3ad3e-aa80-4352-ba17-d9f307a0552e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH MaxTripDistance AS (\n",
      "    SELECT MAX(trip_distance) AS max_distance\n",
      "    FROM green_trip_data\n",
      ")\n",
      "\n",
      "SELECT lpep_pickup_datetime\n",
      "FROM green_trip_data\n",
      "WHERE trip_distance = (SELECT max_distance FROM MaxTripDistance);\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL STATEMENT \n",
    "\"\"\" SELECT MAX(trip_distance) FROM green_trip_data ;\n",
    "    SELECT lpep_pickup_datetime FROM green_trip_data \n",
    "    WHERE trip_distance = 341.64;\n",
    "\"\"\"\n",
    "print(\"\"\"WITH MaxTripDistance AS (\n",
    "    SELECT MAX(trip_distance) AS max_distance\n",
    "    FROM green_trip_data\n",
    ")\n",
    "\n",
    "SELECT lpep_pickup_datetime\n",
    "FROM green_trip_data\n",
    "WHERE trip_distance = (SELECT max_distance FROM MaxTripDistance);\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea62436a-304b-475a-80c1-a5bb81167cba",
   "metadata": {},
   "source": [
    "## Question 5. Three biggest pick up Boroughs\r\n",
    "Consider lpep_pickup_datetime in '2019-09-18' and ignoring Borough has Unknown\r\n",
    "\r\n",
    "Which were the 3 pick up Boroughs that had a sum of total_amount superior to 50000?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8345a52-d567-489a-8ddd-4811874b5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT taxi_zone_lookup.*, green_trip_data.\"total_amount\"\n",
    "FROM taxi_zone_lookup\n",
    "JOIN green_trip_data ON \"PULocationID\" = \"LocationID\"  \n",
    "WHERE green_trip_data.total_amount > 5000;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
