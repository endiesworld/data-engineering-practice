{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f934d55f-1ce5-404d-9c73-e63a0f264afd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import time \n",
    "\n",
    "from kafka import KafkaProducer\n",
    "\n",
    "def json_serializer(data):\n",
    "    return json.dumps(data).encode('utf-8')\n",
    "\n",
    "server = 'localhost:9092'\n",
    "\n",
    "producer = KafkaProducer(\n",
    "    bootstrap_servers=[server],\n",
    "    value_serializer=json_serializer\n",
    ")\n",
    "\n",
    "producer.bootstrap_connected()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e13595-b7ec-4f4b-9a0a-ed63c21d0c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sent: {'number': 0}\n",
      "Sent: {'number': 1}\n",
      "Sent: {'number': 2}\n",
      "Sent: {'number': 3}\n",
      "Sent: {'number': 4}\n",
      "Sent: {'number': 5}\n",
      "Sent: {'number': 6}\n",
      "Sent: {'number': 7}\n",
      "Sent: {'number': 8}\n",
      "Sent: {'number': 9}\n",
      "took 0.56 seconds\n",
      "data sent\n",
      "took 0.00 seconds\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "topic_name = 'test-topic'\n",
    "\n",
    "for i in range(10):\n",
    "    message = {'number': i}\n",
    "    producer.send(topic_name, value=message)\n",
    "    print(f\"Sent: {message}\")\n",
    "    time.sleep(0.05)\n",
    "    \n",
    "t1 = time.time()\n",
    "print(f'took {(t1 - t0):.2f} seconds')\n",
    "print(\"data sent\")\n",
    "producer.flush()\n",
    "\n",
    "t2 = time.time()\n",
    "print(f'took {(t2 - t1):.2f} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05c2a597-a356-484c-9222-c87ecddb7f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-04-07 11:45:50--  https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240407%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240407T104549Z&X-Amz-Expires=300&X-Amz-Signature=429d84358e8c00b2d5c7b61321386bb526b8710e071860e7b57231bd5b85e69f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream [following]\n",
      "--2024-04-07 11:45:51--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/513814948/ea580e9e-555c-4bd0-ae73-43051d8e7c0b?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240407%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240407T104549Z&X-Amz-Expires=300&X-Amz-Signature=429d84358e8c00b2d5c7b61321386bb526b8710e071860e7b57231bd5b85e69f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=513814948&response-content-disposition=attachment%3B%20filename%3Dgreen_tripdata_2019-10.csv.gz&response-content-type=application%2Foctet-stream\n",
      "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 8262584 (7.9M) [application/octet-stream]\n",
      "Saving to: ‘data/green_tripdata_2019-10.csv.gz’\n",
      "\n",
      "data/green_tripdata 100%[===================>]   7.88M   963KB/s    in 9.7s    \n",
      "\n",
      "2024-04-07 11:46:04 (835 KB/s) - ‘data/green_tripdata_2019-10.csv.gz’ saved [8262584/8262584]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create the directory (replace \"data\" with your desired directory name)\n",
    "!mkdir data\n",
    "\n",
    "# Download the file with the directory included in the path\n",
    "!wget https://github.com/DataTalksClub/nyc-tlc-data/releases/download/green/green_tripdata_2019-10.csv.gz -O \"data/green_tripdata_2019-10.csv.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e80eccf-a384-486f-886c-c7e1305c499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace \"../../../../\" with the actual absolute path to your home directory\n",
    "home_directory = \"../../../../../\"\n",
    "os.environ[\"SPARK_HOME\"] = os.path.join(home_directory, \"spark-3.3.2-bin-hadoop3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d8768f2-31fe-4300-972f-5ee3665f2106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97f4c374-38e2-4bea-a820-174cc998b22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/08 06:10:14 WARN Utils: Your hostname, Endiesworld resolves to a loopback address: 127.0.1.1; using 172.22.195.180 instead (on interface eth0)\n",
      "24/04/08 06:10:14 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/04/08 06:10:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.types as T\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark-Notebook\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc5940d0-48b1-48a9-a1e6-e4b3659f11b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- lpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- lpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- ehail_fee: string (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- trip_type: integer (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|VendorID|lpep_pickup_datetime|lpep_dropoff_datetime|store_and_fwd_flag|RatecodeID|PULocationID|DOLocationID|passenger_count|trip_distance|fare_amount|extra|mta_tax|tip_amount|tolls_amount|ehail_fee|improvement_surcharge|total_amount|payment_type|trip_type|congestion_surcharge|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "|       2| 2019-10-01 00:26:02|  2019-10-01 00:39:58|                 N|         1|         112|         196|              1|         5.88|       18.0|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|        19.3|           2|        1|                 0.0|\n",
      "|       1| 2019-10-01 00:18:11|  2019-10-01 00:22:38|                 N|         1|          43|         263|              1|          0.8|        5.0| 3.25|    0.5|       0.0|         0.0|     null|                  0.3|        9.05|           2|        1|                 0.0|\n",
      "|       1| 2019-10-01 00:09:31|  2019-10-01 00:24:47|                 N|         1|         255|         228|              2|          7.5|       21.5|  0.5|    0.5|       0.0|         0.0|     null|                  0.3|        22.8|           2|        1|                 0.0|\n",
      "+--------+--------------------+---------------------+------------------+----------+------------+------------+---------------+-------------+-----------+-----+-------+----------+------------+---------+---------------------+------------+------------+---------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define path to the file, including the .gz extension\n",
    "file_path = \"data/green_tripdata_2019-10.csv.gz\"\n",
    "\n",
    "# Read the data as a DataFrame with options for header and compression\n",
    "# df = spark.read.option(\"header\", True).option(\"compression\", \"gzip\").csv(file_path)\n",
    "df = spark.read.option(\"header\", \"true\").option(\"compression\", \"gzip\").option(\"inferSchema\", \"true\").csv(file_path)\n",
    "\n",
    "\n",
    "# Show the schema and the first few rows (optional)\n",
    "df.printSchema()\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32d9abf3-199b-4545-ae94-d226a767c9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['lpep_pickup_datetime', 'lpep_dropoff_datetime', 'PULocationID','DOLocationID','passenger_count','trip_distance','tip_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea5c9987-7377-49be-9059-b80c22dc862d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Columns:\n",
      "+--------------------+---------------------+------------+------------+---------------+-------------+----------+\n",
      "|lpep_pickup_datetime|lpep_dropoff_datetime|PULocationID|DOLocationID|passenger_count|trip_distance|tip_amount|\n",
      "+--------------------+---------------------+------------+------------+---------------+-------------+----------+\n",
      "| 2019-10-01 00:26:02|  2019-10-01 00:39:58|         112|         196|              1|         5.88|       0.0|\n",
      "| 2019-10-01 00:18:11|  2019-10-01 00:22:38|          43|         263|              1|          0.8|       0.0|\n",
      "| 2019-10-01 00:09:31|  2019-10-01 00:24:47|         255|         228|              2|          7.5|       0.0|\n",
      "+--------------------+---------------------+------------+------------+---------------+-------------+----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select specific columns\n",
    "selected_columns = df.select(columns)\n",
    "print(\"Selected Columns:\")\n",
    "selected_columns.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "27c830a9-22f4-49d2-8056-ee40b162b87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lpep_pickup_datetime': '2019-10-01 00:26:02', 'lpep_dropoff_datetime': '2019-10-01 00:39:58', 'PULocationID': '112', 'DOLocationID': '196', 'passenger_count': '1', 'trip_distance': '5.88', 'tip_amount': '0.0'}\n"
     ]
    }
   ],
   "source": [
    "for row in selected_columns.collect():\n",
    "    row_dict = row.asDict()\n",
    "    data = {}\n",
    "    for column_name, column_value in row_dict.items():\n",
    "        data[column_name] = \"{}\".format(column_value)\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "660cbf4c-fbaf-47a6-b230-efdda206f9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "took 185.60 seconds to send data\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "topic_name = 'green-trips'\n",
    "\n",
    "for row in selected_columns.collect():\n",
    "    row_dict = row.asDict()\n",
    "    data = {}\n",
    "    for column_name, column_value in row_dict.items():\n",
    "        data[column_name] = \"{}\".format(column_value)\n",
    "    producer.send(topic_name, value=data)\n",
    "    \n",
    "\n",
    "producer.flush()\n",
    "\n",
    "t1 = time.time()\n",
    "print(f'took {(t1 - t0):.2f} seconds to send data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f620dbb-00b6-4673-bcfa-ba52bb016773",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_dict = {col: getattr(row, col) for col in row._fields}\n",
    "#     print(row_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6077f6a4-38d7-4e08-85df-6cb6b1b05c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assuming 'df_spark' is your PySpark DataFrame\n",
    "# from pyspark.sql.functions import col\n",
    "\n",
    "# # Convert timezone-aware datetime column to timezone-naive\n",
    "# df_spark = selected_columns.withColumn('lpep_pickup_datetime', col('lpep_pickup_datetime').cast('timestamp'))\n",
    "# df_spark = df_spark.withColumn('lpep_pickup_datetime', col('lpep_pickup_datetime').cast('timestamp'))\n",
    "\n",
    "# # Convert PySpark DataFrame to Pandas DataFrame\n",
    "# pandas_df = df_spark.toPandas()\n",
    "# pandas_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8de08fa7-fc9e-4239-ae3b-7c48ae4330b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas_df = selected_columns.toPandas().astype({'lpep_pickup_datetime': 'datetime64[ns]', 'lpep_dropoff_datetime': 'datetime64[ns]'})\n",
    "\n",
    "\n",
    "# for row in pandas_df.itertuples(index=False):\n",
    "#     row_dict = {col: getattr(row, col) for col in row._fields}\n",
    "#     print(row_dict)\n",
    "#     break\n",
    "\n",
    "#     # TODO implement sending the data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d821b4e-7c9e-47f8-b35b-787fe085c609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t0 = time.time()\n",
    "\n",
    "# topic_name = 'green-trips'\n",
    "\n",
    "# for i in range(10):\n",
    "#     message = {'number': i}\n",
    "#     producer.send(topic_name, value=message)\n",
    "#     print(f\"Sent: {message}\")\n",
    "#     time.sleep(0.05)\n",
    "    \n",
    "# t1 = time.time()\n",
    "# print(f'took {(t1 - t0):.2f} seconds')\n",
    "# print(\"data sent\")\n",
    "# producer.flush()\n",
    "\n",
    "# t2 = time.time()\n",
    "# print(f'took {(t2 - t1):.2f} seconds')\n",
    "\n",
    "# Define a function to process each row\n",
    "def process_row(row):\n",
    "    row_dict = {col: getattr(row, col) for col in row._fields}\n",
    "    print(row_dict)\n",
    "\n",
    "# Apply the function to each row\n",
    "df.foreach(process_row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
