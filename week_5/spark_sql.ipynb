{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4083d743-de85-4275-94f2-4894135c97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Replace \"../../../../\" with the actual absolute path to your home directory\n",
    "home_directory = \"../../../../\"\n",
    "os.environ[\"SPARK_HOME\"] = os.path.join(home_directory, \"spark-3.3.2-bin-hadoop3\")\n",
    "spark_python = os.path.join(os.environ[\"SPARK_HOME\"], \"python\")\n",
    "py4j_path = os.path.join(spark_python, \"lib\", \"py4j-*.zip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9890596e-d824-4c55-9973-1ce390fbf78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/24 11:27:20 WARN Utils: Your hostname, Endiesworld resolves to a loopback address: 127.0.1.1; using 172.22.195.180 instead (on interface eth0)\n",
      "24/02/24 11:27:20 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/02/24 11:27:24 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.22.195.180:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>spark_sql</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fdd7b701dc0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"spark_sql\") \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbceb6ab-abc1-4130-9c88-8dec1bc7ea47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name,age,gender,salary\n",
      "John Doe,30,Male,50000\n",
      "Jane Smith,25,Female,45000\n",
      "David Johnson,35,Male,60000\n",
      "Emily Davis,28,Female,52000\n",
      "Michael Wilson,40,Male,75000\n",
      "Sarah Brown,32,Female,58000\n",
      "Robert Lee,29,Male,51000\n",
      "Lisa Garcia,27,Female,49000\n",
      "James Martinez,38,Male,70000\n"
     ]
    }
   ],
   "source": [
    "!head -10 persons.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500e3666-171a-4dd3-a9b4-0d0014eaeea3",
   "metadata": {},
   "source": [
    "## Load Data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f60872bf-d990-49fb-85d0-cec4c7238968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load the synthetic data into a DataFrame\n",
    "data_file_path = \"persons.csv\"\n",
    "df = spark.read.csv(data_file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c3d9325-95e7-4461-bb74-6e621cc059b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n",
      "Initial DataFrame:\n",
      "+------------------+---+------+------+\n",
      "|              name|age|gender|salary|\n",
      "+------------------+---+------+------+\n",
      "|          John Doe| 30|  Male| 50000|\n",
      "|        Jane Smith| 25|Female| 45000|\n",
      "|     David Johnson| 35|  Male| 60000|\n",
      "|       Emily Davis| 28|Female| 52000|\n",
      "|    Michael Wilson| 40|  Male| 75000|\n",
      "|       Sarah Brown| 32|Female| 58000|\n",
      "|        Robert Lee| 29|  Male| 51000|\n",
      "|       Lisa Garcia| 27|Female| 49000|\n",
      "|    James Martinez| 38|  Male| 70000|\n",
      "|Jennifer Rodriguez| 26|Female| 47000|\n",
      "+------------------+---+------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Show the initial DataFrame\n",
    "print(\"Initial DataFrame:\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b1b534-82c4-4dc8-9b39-8a736d763edd",
   "metadata": {},
   "source": [
    "## Register the DataFrame as a Temporary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c4ec9d4-3e1e-4a3d-b5a5-e6c799e71150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the DataFrame as a Temporary Table\n",
    "df.createOrReplaceTempView(\"my_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f98486-cd2f-47e7-917b-6ff9d91a98d6",
   "metadata": {},
   "source": [
    "## Perform SQL-like Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d53cee-927b-4076-998b-226a45e523b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+------+------+\n",
      "|              name|age|gender|salary|\n",
      "+------------------+---+------+------+\n",
      "|          John Doe| 30|  Male| 50000|\n",
      "|     David Johnson| 35|  Male| 60000|\n",
      "|       Emily Davis| 28|Female| 52000|\n",
      "|    Michael Wilson| 40|  Male| 75000|\n",
      "|       Sarah Brown| 32|Female| 58000|\n",
      "|        Robert Lee| 29|  Male| 51000|\n",
      "|       Lisa Garcia| 27|Female| 49000|\n",
      "|    James Martinez| 38|  Male| 70000|\n",
      "|Jennifer Rodriguez| 26|Female| 47000|\n",
      "|  William Anderson| 33|  Male| 62000|\n",
      "|   Karen Hernandez| 31|Female| 55000|\n",
      "|Christopher Taylor| 37|  Male| 69000|\n",
      "|     Matthew Davis| 36|  Male| 67000|\n",
      "|    Patricia White| 29|Female| 50000|\n",
      "|     Daniel Miller| 34|  Male| 64000|\n",
      "| Elizabeth Jackson| 30|Female| 52000|\n",
      "|     Joseph Harris| 28|  Male| 53000|\n",
      "|      Linda Martin| 39|Female| 71000|\n",
      "+------------------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select all rows where age is greater than 25\n",
    "result = spark.sql(\"SELECT * FROM my_table WHERE age > 25\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94ef2be1-cb28-4df9-8618-ee5441625a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|gender|avg_salary|\n",
      "+------+----------+\n",
      "|Female|   52300.0|\n",
      "|  Male|   62100.0|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the average salary by gender\n",
    "avg_salary_by_gender = spark.sql(\"SELECT gender, AVG(salary) as avg_salary FROM my_table GROUP BY gender\")\n",
    "avg_salary_by_gender.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287544cb-fe08-4c9b-974d-545c69cf6ebb",
   "metadata": {},
   "source": [
    "## Creating and managing temporary views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "302b104f-80f8-4f88-bbb4-56127a2cd95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary view\n",
    "df.createOrReplaceTempView(\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4faa5015-1995-4180-a29b-d96a75df4489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+------+------+\n",
      "|              name|age|gender|salary|\n",
      "+------------------+---+------+------+\n",
      "|          John Doe| 30|  Male| 50000|\n",
      "|     David Johnson| 35|  Male| 60000|\n",
      "|       Emily Davis| 28|Female| 52000|\n",
      "|    Michael Wilson| 40|  Male| 75000|\n",
      "|       Sarah Brown| 32|Female| 58000|\n",
      "|        Robert Lee| 29|  Male| 51000|\n",
      "|       Lisa Garcia| 27|Female| 49000|\n",
      "|    James Martinez| 38|  Male| 70000|\n",
      "|Jennifer Rodriguez| 26|Female| 47000|\n",
      "|  William Anderson| 33|  Male| 62000|\n",
      "|   Karen Hernandez| 31|Female| 55000|\n",
      "|Christopher Taylor| 37|  Male| 69000|\n",
      "|     Matthew Davis| 36|  Male| 67000|\n",
      "|    Patricia White| 29|Female| 50000|\n",
      "|     Daniel Miller| 34|  Male| 64000|\n",
      "| Elizabeth Jackson| 30|Female| 52000|\n",
      "|     Joseph Harris| 28|  Male| 53000|\n",
      "|      Linda Martin| 39|Female| 71000|\n",
      "+------------------+---+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the temporary view\n",
    "result = spark.sql(\"SELECT * FROM people WHERE age > 25\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54778df9-ffe5-495c-80ed-7c57cba2dd46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop a temporary view\n",
    "spark.catalog.dropTempView(\"people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31340fad-b5bd-4b92-90f1-1936ffcbbb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if a temporary view exists\n",
    "view_exists = spark.catalog.tableExists(\"people\")\n",
    "view_exists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a367ff-46b8-4bfb-ae38-83481b6566b6",
   "metadata": {},
   "source": [
    "## Subquries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08726352-958f-4246-9c08-f1cdcaf67e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| id|   name|\n",
      "+---+-------+\n",
      "|  1|   John|\n",
      "|  2|  Alice|\n",
      "|  3|    Bob|\n",
      "|  4|  Emily|\n",
      "|  5|  David|\n",
      "|  6|  Sarah|\n",
      "|  7|Michael|\n",
      "|  8|   Lisa|\n",
      "|  9|William|\n",
      "+---+-------+\n",
      "\n",
      "+----------+---+------+\n",
      "|department| id|salary|\n",
      "+----------+---+------+\n",
      "|        HR|  1| 60000|\n",
      "|        HR|  2| 55000|\n",
      "|        HR|  3| 58000|\n",
      "|        IT|  4| 70000|\n",
      "|        IT|  5| 72000|\n",
      "|        IT|  6| 68000|\n",
      "|     Sales|  7| 75000|\n",
      "|     Sales|  8| 78000|\n",
      "|     Sales|  9| 77000|\n",
      "+----------+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create DataFrames\n",
    "employee_data = [\n",
    "    (1, \"John\"), (2, \"Alice\"), (3, \"Bob\"), (4, \"Emily\"),\n",
    "    (5, \"David\"), (6, \"Sarah\"), (7, \"Michael\"), (8, \"Lisa\"),\n",
    "    (9, \"William\")\n",
    "]\n",
    "employees = spark.createDataFrame(employee_data, [\"id\", \"name\"])\n",
    "\n",
    "salary_data = [\n",
    "    (\"HR\", 1, 60000), (\"HR\", 2, 55000), (\"HR\", 3, 58000),\n",
    "    (\"IT\", 4, 70000), (\"IT\", 5, 72000), (\"IT\", 6, 68000),\n",
    "    (\"Sales\", 7, 75000), (\"Sales\", 8, 78000), (\"Sales\", 9, 77000)\n",
    "]\n",
    "salaries = spark.createDataFrame(salary_data, [\"department\", \"id\", \"salary\"])\n",
    "\n",
    "employees.show()\n",
    "\n",
    "salaries.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2caceaa-a092-4f35-9f2f-9c2b934eb147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register as temporary views\n",
    "employees.createOrReplaceTempView(\"employees\")\n",
    "salaries.createOrReplaceTempView(\"salaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a70015e-505c-4e2b-b434-407ba15a0f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|  Emily|\n",
      "|  David|\n",
      "|Michael|\n",
      "|   Lisa|\n",
      "|William|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subquery to find employees with salaries above average\n",
    "result = spark.sql(\"\"\"\n",
    "    SELECT name\n",
    "    FROM employees\n",
    "    WHERE id IN (\n",
    "        SELECT id\n",
    "        FROM salaries\n",
    "        WHERE salary > (SELECT AVG(salary) FROM salaries)\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032f9c33-7b77-404b-a21e-d8feab7b397e",
   "metadata": {},
   "source": [
    "## Window Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3f5871e-f5bd-4416-a61e-08f7de90d81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de968ee1-07e3-4dd4-8d02-de2d9252c829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+-------+\n",
      "|department| id|salary|   name|\n",
      "+----------+---+------+-------+\n",
      "|        HR|  1| 60000|   John|\n",
      "|        HR|  2| 55000|  Alice|\n",
      "|        HR|  3| 58000|    Bob|\n",
      "|        IT|  4| 70000|  Emily|\n",
      "|        IT|  5| 72000|  David|\n",
      "|        IT|  6| 68000|  Sarah|\n",
      "|     Sales|  7| 75000|Michael|\n",
      "|     Sales|  9| 77000|William|\n",
      "|     Sales|  8| 78000|   Lisa|\n",
      "+----------+---+------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "employee_salary = spark.sql(\"\"\"\n",
    "    select  salaries.*, employees.name\n",
    "    from salaries \n",
    "    left join employees on salaries.id = employees.id\n",
    "\"\"\")\n",
    "\n",
    "employee_salary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70522d7f-e30e-4b9b-aee6-580aedaf44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a window specification\n",
    "window_spec = Window.partitionBy(\"department\").orderBy(F.desc(\"salary\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "759493c4-0102-495f-8e17-f4648b245ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+------+-------+----+\n",
      "|department| id|salary|   name|rank|\n",
      "+----------+---+------+-------+----+\n",
      "|        HR|  1| 60000|   John|   1|\n",
      "|        HR|  3| 58000|    Bob|   2|\n",
      "|        HR|  2| 55000|  Alice|   3|\n",
      "|        IT|  5| 72000|  David|   1|\n",
      "|        IT|  4| 70000|  Emily|   2|\n",
      "|        IT|  6| 68000|  Sarah|   3|\n",
      "|     Sales|  8| 78000|   Lisa|   1|\n",
      "|     Sales|  9| 77000|William|   2|\n",
      "|     Sales|  7| 75000|Michael|   3|\n",
      "+----------+---+------+-------+----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate the rank of employees within each department based on salary\n",
    "employee_salary.withColumn(\"rank\", F.rank().over(window_spec)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33ce2e05-98f3-48ae-bcb1-eee9e11fd000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22edbfd-12da-41bd-9342-470d123daf42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
